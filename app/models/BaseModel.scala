package models

import java.sql.Timestamp

/**
  * Created by chenkaiming on 2018/12/25.
  */
abstract class BaseModel extends Serializable

case class SparkApp(appId: String,
                    appName: String,
                    attemptId: String,
                    queue: String,
                    trackingUrl: String,
                    user: String,
                    sparkUser: String,
                    vcoreSeconds: Long,
                    memorySeconds: Long,
                    startTime: Timestamp,
                    endTime: Timestamp,
                    status: String,
                    viewAcls: String,
                    adminAclsGroups: String,
                    cluster: String) extends BaseModel

case class SparkExecutor(appId: String,
                         executorId: String,
                         hostPort: String,
                         rddBlocks: Int,
                         memUsed: Long,
                         maxMem: Long,
                         diskUsed: Long,
                         completedTasks: Int,
                         failedTasks: Int,
                         totalTasks: Int,
                         duration: Long,
                         inputBytes: Long,
                         outputBytes: Long,
                         shuffleRead: Long,
                         shuffleWrite: Long,
                         inputRecord: Long,
                         outputRecord: Long,
                         stdout: String,
                         stderr: String,
                         startTime: Timestamp,
                         finishTime: Timestamp,
                         finishReason: String,
                         cluster: String) extends BaseModel

case class SparkEnv(appId: String,
                    jvmInfo: String,
                    sparkProps: String,
                    sysProps: String,
                    classPath: String,
                    cluster: String) extends BaseModel

case class SparkJob(appId: String,
                    jobId: Int,
                    jobGroup: String,
                    stageIds: String,
                    submissionTime: Timestamp,
                    completedTime: Timestamp,
                    status: String,
                    error: String,
                    failedStageIds: String,
                    numTasks: Int,
                    numActiveTasks: Int,
                    numCompletedTasks: Int,
                    numSkippedTasks: Int,
                    numFailedTasks: Int,
                    numKilledTasks: Int,
                    taskFailureRate: Double,
                    numActiveStages: Int,
                    numSkippedStages: Int,
                    numFailedStages: Int,
                    cluster: String) extends BaseModel

case class SparkStage(appId: String,
                      jobId: Int,
                      stageId: Int,
                      attemptId: Int,
                      parentStageId: String,
                      name: String,
                      description: String,
                      accumulables: String,
                      status: String,
                      failureReason: String,
                      numActiveTasks: Int,
                      numKilledTasks: Int,
                      numCompleteTasks: Int,
                      numFailedTasks: Int,
                      executorRunTime: Long,
                      executorCpuTime: Long,
                      duration: Long,
                      inputBytes: Long,
                      inputRecords: Long,
                      outputBytes: Long,
                      outputRecords: Long,
                      shuffleReadBytes: Long,
                      shuffleReadRecords: Long,
                      shuffleWriteBytes: Long,
                      shuffleWriteRecords: Long,
                      memoryBytesSpilled: Long,
                      diskBytesSpilled: Long,
                      cluster: String) extends BaseModel

case class SparkTask(appId: String,
                     jobId: Int,
                     stageId: Int,
                     executorId: String,
                     taskId: Long,
                     attemptId: Int,
                     launchTime: Timestamp,
                     finishTime: Timestamp,
                     duration: Long,
                     gettingResultTime: Long,
                     status: String,
                     accumulables: String,
                     host: String,
                     locality: String,
                     errorMessage: String,
                     executorDeserTime: Long,
                     executorDeserCpuTime: Long,
                     executorRunTime: Long,
                     executorCpuTime: Long,
                     resultSize: Long,
                     jvmGCTime: Long,
                     resultSerialTime: Long,
                     memoryBytesSpilled: Long,
                     diskBytesSpilled: Long,
                     peakExecutionMemory: Long,
                     inputBytesRead: Long,
                     inputRecordRead: Long,
                     outputBytesWritten: Long,
                     outputRecordsWritten: Long,
                     shuffleRemoteBlocksFetched: Long,
                     shuffleLocalBlocksFetched: Long,
                     shuffleRemoteBytesRead: Long,
                     shuffleLocalBytesRead: Long,
                     shuffleFetchWaitTime: Long,
                     shuffleRecordsRead: Long,
                     shuffleBytesWritten: Long,
                     shuffleRecordsWritten: Long,
                     shuffleWriteTime: Long,
                     cluster: String) extends BaseModel

case class SparkStorage(appId: String,
                        executorId: String,
                        host: String,
                        port: Int,
                        blkmngrId: String,
                        maxMemory: Long,
                        cacheSize: Long,
                        diskUsed: Long,
                        memUsed: Long,
                        memRemaining: Long,
                        numBlocks: Int,
                        numRddBlocks: Int,
                        cluster: String) extends BaseModel